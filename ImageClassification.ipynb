{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "0qO1CX6t4AKc",
        "Qx2zV98l4Nw_"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ICook094/ECEN-4273-Proj2/blob/Google-Colab/ImageClassification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imports and data loads\n",
        "import torch\n",
        "import numpy as np\n",
        "import argparse\n",
        "import cv2 as cv      #OpenCV-python\n",
        "import pydoc"
      ],
      "metadata": {
        "id": "uJBW9UwJ4jlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d4YH2si5AwTh",
        "outputId": "4346d87e-b5e1-42b7-eaa3-40a337e4b202"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (1.21.6)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load Test Images:"
      ],
      "metadata": {
        "id": "UJCalSbj3332"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "torch.utils.data.DataLoader\n",
        "torch.utils.data.Dataset\n",
        "\n",
        "from torchvision import datasets \n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "# input video \n",
        "# https://appdividend.com/2022/10/18/python-cv2-videocapture/\n",
        "vid = cv.VideoCapture('input.mp4') # may need to modify name      *FINISH*\n",
        "\n",
        "while(vid.isOpened()):\n",
        "    ret, frame = vid.read()\n",
        "    # to convert to grayscale\n",
        "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "\n",
        "    cv.imshow('frame', frame)\n",
        "\n",
        "    # cv2.waitKey(1) will ensure the frame of video is displayed for at \n",
        "    # least 1 ms. if waitKey(0), next frame would not be loaded until a \n",
        "    # key press. Thus: waitKey(1) -> video | waitKey(0) -> image\n",
        "\n",
        "    if cv.waitKey(1) & 0xFF == ord('q'): # the Q key to stoppy\n",
        "        break\n",
        "\n",
        "vid.release() # be free\n",
        "cv.destroyAllWindows() # destroy all\n"
      ],
      "metadata": {
        "id": "eNdbS72Z4VB8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Premade datasets from torch-vision \\\\\n",
        "https://pytorch.org/vision/stable/datasets.html\n",
        "\n",
        "Example with video inputs: \\\\\n",
        "https://pytorch.org/vision/stable/auto_examples/plot_video_api.html#sphx-glr-auto-examples-plot-video-api-py"
      ],
      "metadata": {
        "id": "wmJFL5Bz9b1z"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Save data to output video:"
      ],
      "metadata": {
        "id": "UjC9BxlGKC1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# output video \n",
        "# https://appdividend.com/2022/10/18/python-cv2-videocapture/\n",
        "\n",
        "# set resolution. Dounble check these values                      *FINISH*\n",
        "frame_width = int(vid.get(3))\n",
        "frame_height = int(vid.get(4))\n",
        "size = (frame_width, frame_height)\n",
        "\n",
        "# use cv.VideoWrite to combine frames into an output video\n",
        "result = cv.VideoWriter('output.mp4', cv.VideoWriter_fourcc(*'MP4V'),\n",
        "                         10, size)\n",
        "# unsure if them four codex thingy is correct. Needs testing      *FINISH*\n",
        "# i also idk about the 10 frames. Needs testing                   *FINISH*\n",
        "\n",
        "while(True):\n",
        "    ret, frame = vid.read()\n",
        "    # to convert to grayscale\n",
        "    # gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
        "    if ret == True:\n",
        "      result.write(frame)\n",
        "      cv.imshow('frame', frame)\n",
        "\n",
        "      if cv.waitKey(1) & 0xFF == ord('q'): # the Q key to stoppy\n",
        "          break\n",
        "    else: \n",
        "      break\n",
        "\n",
        "result.reslease() # part 2\n",
        "cv.destroyAllWindows() # destroy all"
      ],
      "metadata": {
        "id": "71Fe7PQjJ_fr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Neural Network:"
      ],
      "metadata": {
        "id": "0qO1CX6t4AKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchsummary import summary"
      ],
      "metadata": {
        "id": "9Az1lLe14ZIF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Train:"
      ],
      "metadata": {
        "id": "swOMthWP4KsR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Training will be done via Supervised Learning (aka Backpropagation)"
      ],
      "metadata": {
        "id": "jfkuQ9PI-npg"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L2E2lt7x4Zs5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test:"
      ],
      "metadata": {
        "id": "Qx2zV98l4Nw_"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "E37bQW8F4aJl"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}